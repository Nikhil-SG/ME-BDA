# -*- coding: utf-8 -*-
"""ML_Challenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zFWNowdAsbV9nE723SrM0X3KfeTCNotD
"""

!pip install pytesseract

!sudo apt install tesseract-ocr
!sudo apt install libtesseract-dev

import requests
from PIL import Image, ImageEnhance
import pytesseract
import io
import cv2
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO

# Function to download and display image
def download_image(image_url):
    response = requests.get(image_url)
    img = Image.open(BytesIO(response.content))
    return img

# Function to display image
def display_image(img):
    plt.imshow(img)
    plt.axis('off')  # Hide axes
    plt.show()

# Function to increase contrast
def increase_contrast(image, factor=2):
    enhancer = ImageEnhance.Contrast(image)
    enhanced_img = enhancer.enhance(factor)  # Increase contrast by a factor of 2
    return enhanced_img

# Function to upscale image
def upscale_image(image, scale_factor=2):
    width, height = image.size
    new_size = (int(width * scale_factor), int(height * scale_factor))
    return image.resize(new_size, Image.ANTIALIAS)

# Function to preprocess image for Tesseract (convert to grayscale, etc.)
def preprocess_image(image):
    img = np.array(image)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale
    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)  # Thresholding
    return Image.fromarray(binary)

# Function to extract text using Tesseract
def extract_text(image, psm=6):
    custom_config = f'--psm {psm}'  # Page segmentation mode
    text = pytesseract.image_to_string(image, config=custom_config)
    return text

# Function to crop image
def crop_image(img, box):
    """Crop the image to focus on the area where text is located."""
    cropped_img = img.crop(box)
    return cropped_img

# Function to perform the full OCR pipeline
def ocr_pipeline(image_url):
    # Step 1: Download image
    img = download_image(image_url)

    # Step 2: Display the original image
    print("Original Image:")
    display_image(img)

    # Step 3: Increase contrast
    img = increase_contrast(img)
    #print("Image after Contrast Enhancement:")
    #display_image(img)

    # Step 4: Upscale the image to improve OCR accuracy
    img = upscale_image(img)
    #print("Upscaled Image:")
    #display_image(img)

    # Step 5: Preprocess image for OCR
    preprocessed_img = preprocess_image(img)
    print("Preprocessed Image for OCR:")
    display_image(preprocessed_img)

    # Step 6: Extract text using different PSM modes
    for psm_mode in [3, 4, 6, 11]:  # Testing multiple PSM modes
        print(f"Extracted text with PSM {psm_mode}:")
        text = extract_text(preprocessed_img, psm=psm_mode)
        print(text)

    # Optional: If you know where the text is, you can crop the image (Adjust the box as needed)
    box = (50, 50, 300, 300)  # Replace with actual coordinates if necessary
    cropped_img = crop_image(preprocessed_img, box)
    print("Cropped Image:")
    display_image(cropped_img)

    # Final OCR on cropped image (if necessary)
    print("Extracted text from cropped image:")
    text = extract_text(cropped_img)
    print(text)

# Test the OCR pipeline with the provided image URL
image_url = 'https://m.media-amazon.com/images/I/71iSbwHDcdL.jpg'
  # Replace with your image URL
ocr_pipeline(image_url)