{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b03d1-4d15-4dc0-8892-80c81fe87886",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Sales Data Analysis\n",
    "Use Case: Analyze sales data for trends, customer segmentation, or performance.\n",
    "Operations:\n",
    "Count total sales per product category.\n",
    "Calculate the total revenue generated by each sales representative.\n",
    "Find the product with the highest sales.\n",
    "Group data by sales regions and calculate average sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fd53961-4b3d-407e-98d2-df05dfa4f679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ProductCategory SalesRepresentative Product Region  SalesAmount\n",
      "0     Electronics                John   Phone  North          200\n",
      "1       Furniture                 Doe   Table   West          300\n",
      "2        Clothing               Alice   Shirt   East          150\n",
      "3     Electronics                 Doe  Laptop  North          400\n",
      "4        Clothing                John   Pants   East          100\n",
      "5       Furniture               Alice   Chair   West          250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'ProductCategory': ['Electronics', 'Furniture', 'Clothing', 'Electronics', 'Clothing', 'Furniture'],\n",
    "    'SalesRepresentative': ['John', 'Doe', 'Alice', 'Doe', 'John', 'Alice'],\n",
    "    'Product': ['Phone', 'Table', 'Shirt', 'Laptop', 'Pants', 'Chair'],\n",
    "    'Region': ['North', 'West', 'East', 'North', 'East', 'West'],\n",
    "    'SalesAmount': [200, 300, 150, 400, 100, 250]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d22d777-6363-4292-92ec-1bdbd28a4c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>SalesAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clothing</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Furniture</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProductCategory  SalesAmount\n",
       "0        Clothing          250\n",
       "1     Electronics          600\n",
       "2       Furniture          550"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Count total sales per product category\n",
    "total_sales_per_category = df.groupby('ProductCategory')['SalesAmount'].sum().reset_index()\n",
    "total_sales_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9923530-6c7d-4fcd-a246-a1f64b50a85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesRepresentative</th>\n",
       "      <th>SalesAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doe</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SalesRepresentative  SalesAmount\n",
       "0               Alice          400\n",
       "1                 Doe          700\n",
       "2                John          300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Calculate total revenue by sales representative\n",
    "total_revenue_by_rep = df.groupby('SalesRepresentative')['SalesAmount'].sum().reset_index()\n",
    "total_revenue_by_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "693a6e5e-12b3-4199-a86e-c2d92833be6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laptop'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Find the product with the highest sales\n",
    "product_with_highest_sales = df.groupby('Product')['SalesAmount'].sum().idxmax()\n",
    "product_with_highest_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c7d85f8-43f9-4ce9-a221-dd4ef7d649dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>SalesAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Region  SalesAmount\n",
       "0   East        125.0\n",
       "1  North        300.0\n",
       "2   West        275.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Group by sales region and calculate average sales\n",
    "average_sales_by_region = df.groupby('Region')['SalesAmount'].mean().reset_index()\n",
    "average_sales_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b64a5f-c5a2-4ec7-b5b9-160ac9774e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Employee Data Analysis\n",
    "Use Case: Manage and analyze employee-related data like salaries, departments, and performance.\n",
    "Operations:\n",
    "Count the number of employees per department.\n",
    "Find the employee with the highest salary.\n",
    "Calculate average salary per department.\n",
    "Sort employees based on their performance score or salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29738cfe-d9c1-4223-83d9-47b3d89dea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee_ID     Name Department  Salary  Performance_Score\n",
      "0          101     John         HR   60000                 85\n",
      "1          102     Emma    Finance   75000                 92\n",
      "2          103   Sophia         IT   90000                 88\n",
      "3          104  Michael         HR   62000                 79\n",
      "4          105   Olivia         IT   95000                 95\n",
      "5          106    David    Finance   70000                 90\n",
      "6          107     Liam         HR   58000                 78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample employee data\n",
    "data = {\n",
    "    'Employee_ID': [101, 102, 103, 104, 105, 106, 107],\n",
    "    'Name': ['John', 'Emma', 'Sophia', 'Michael', 'Olivia', 'David', 'Liam'],\n",
    "    'Department': ['HR', 'Finance', 'IT', 'HR', 'IT', 'Finance', 'HR'],\n",
    "    'Salary': [60000, 75000, 90000, 62000, 95000, 70000, 58000],\n",
    "    'Performance_Score': [85, 92, 88, 79, 95, 90, 78]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7110afd7-6c1a-48df-b8a6-bf4990fc9f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department\n",
      "Finance    2\n",
      "HR         3\n",
      "IT         2\n",
      "Name: Employee_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Count the Number of Employees per Department:\n",
    "employees_per_department = df.groupby('Department')['Employee_ID'].count()\n",
    "print(employees_per_department)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59051cd6-7e3a-40a4-bd9d-1783f490798c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employee_ID             105\n",
       "Name                 Olivia\n",
       "Department               IT\n",
       "Salary                95000\n",
       "Performance_Score        95\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.Find the Employee with the Highest Salary\n",
    "highest_salary_employee = df.loc[df['Salary'].idxmax()]\n",
    "highest_salary_employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdab6422-a793-4a57-8e96-730da240a70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department\n",
       "Finance    72500.0\n",
       "HR         60000.0\n",
       "IT         92500.0\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.Calculate Average Salary per Department:\n",
    "avg_salary_per_department = df.groupby('Department')['Salary'].mean()\n",
    "avg_salary_per_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7d82719-993c-4ae0-84a4-159676b8d200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Performance_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>IT</td>\n",
       "      <td>95000</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Finance</td>\n",
       "      <td>75000</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>David</td>\n",
       "      <td>Finance</td>\n",
       "      <td>70000</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>IT</td>\n",
       "      <td>90000</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John</td>\n",
       "      <td>HR</td>\n",
       "      <td>60000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Michael</td>\n",
       "      <td>HR</td>\n",
       "      <td>62000</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Liam</td>\n",
       "      <td>HR</td>\n",
       "      <td>58000</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee_ID     Name Department  Salary  Performance_Score\n",
       "4          105   Olivia         IT   95000                 95\n",
       "1          102     Emma    Finance   75000                 92\n",
       "5          106    David    Finance   70000                 90\n",
       "2          103   Sophia         IT   90000                 88\n",
       "0          101     John         HR   60000                 85\n",
       "3          104  Michael         HR   62000                 79\n",
       "6          107     Liam         HR   58000                 78"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Sort Employees Based on Their Performance Score:\n",
    "sorted_by_performance = df.sort_values('Performance_Score', ascending=False)\n",
    "sorted_by_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5c810db-5b0e-4ced-9a08-470d27c73c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Performance_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>IT</td>\n",
       "      <td>95000</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>Sophia</td>\n",
       "      <td>IT</td>\n",
       "      <td>90000</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Finance</td>\n",
       "      <td>75000</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>David</td>\n",
       "      <td>Finance</td>\n",
       "      <td>70000</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>Michael</td>\n",
       "      <td>HR</td>\n",
       "      <td>62000</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>John</td>\n",
       "      <td>HR</td>\n",
       "      <td>60000</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>Liam</td>\n",
       "      <td>HR</td>\n",
       "      <td>58000</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Employee_ID     Name Department  Salary  Performance_Score\n",
       "4          105   Olivia         IT   95000                 95\n",
       "2          103   Sophia         IT   90000                 88\n",
       "1          102     Emma    Finance   75000                 92\n",
       "5          106    David    Finance   70000                 90\n",
       "3          104  Michael         HR   62000                 79\n",
       "0          101     John         HR   60000                 85\n",
       "6          107     Liam         HR   58000                 78"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort Employees Based on Their Sort by Salary:\n",
    "sorted_by_salary = df.sort_values('Salary', ascending=False)\n",
    "sorted_by_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c559c5-e062-49c3-85c8-9ec49a3f1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Financial Data (Stock Market)\n",
    "Use Case: Perform financial data analysis for stocks, assets, and investments.\n",
    "Operations:\n",
    "Calculate daily, weekly, or monthly stock returns.\n",
    "Find the stock with the highest or lowest closing price.\n",
    "Compute moving averages for stock prices.\n",
    "Group stock data by industry or sector and calculate key metrics like P/E ratio or market cap. create a dataframe first and then answer these questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09c77d99-5535-4ff4-9591-13debed4637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stock_Ticker        Date    Industry                Sector  Closing_Price  \\\n",
      "0         AAPL  2024-09-01        Tech  Consumer Electronics            150   \n",
      "1        GOOGL  2024-09-01        Tech        Search Engines           2800   \n",
      "2         MSFT  2024-09-01        Tech              Software            305   \n",
      "3         TSLA  2024-09-01  Automotive            Automotive            700   \n",
      "4         AMZN  2024-09-01  E-commerce                Retail           3400   \n",
      "5         AAPL  2024-09-02        Tech  Consumer Electronics            152   \n",
      "6        GOOGL  2024-09-02        Tech        Search Engines           2820   \n",
      "7         MSFT  2024-09-02        Tech              Software            310   \n",
      "8         TSLA  2024-09-02  Automotive            Automotive            710   \n",
      "9         AMZN  2024-09-02  E-commerce                Retail           3450   \n",
      "\n",
      "     Market_Cap  P/E_Ratio  \n",
      "0  2.500000e+12         30  \n",
      "1  1.800000e+12         28  \n",
      "2  2.300000e+12         35  \n",
      "3  7.000000e+11         25  \n",
      "4  1.700000e+12         70  \n",
      "5  2.600000e+12         31  \n",
      "6  1.850000e+12         29  \n",
      "7  2.350000e+12         34  \n",
      "8  7.200000e+11         24  \n",
      "9  1.750000e+12         71  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample stock market data\n",
    "data = {\n",
    "    'Stock_Ticker': ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN', 'AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN'],\n",
    "    'Date': ['2024-09-01', '2024-09-01', '2024-09-01', '2024-09-01', '2024-09-01',\n",
    "             '2024-09-02', '2024-09-02', '2024-09-02', '2024-09-02', '2024-09-02'],\n",
    "    'Industry': ['Tech', 'Tech', 'Tech', 'Automotive', 'E-commerce', 'Tech', 'Tech', 'Tech', 'Automotive', 'E-commerce'],\n",
    "    'Sector': ['Consumer Electronics', 'Search Engines', 'Software', 'Automotive', 'Retail', \n",
    "               'Consumer Electronics', 'Search Engines', 'Software', 'Automotive', 'Retail'],\n",
    "    'Closing_Price': [150, 2800, 305, 700, 3400, 152, 2820, 310, 710, 3450],\n",
    "    'Market_Cap': [2.5e12, 1.8e12, 2.3e12, 0.7e12, 1.7e12, 2.6e12, 1.85e12, 2.35e12, 0.72e12, 1.75e12],\n",
    "    'P/E_Ratio': [30, 28, 35, 25, 70, 31, 29, 34, 24, 71]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6783bda2-cfd9-406b-88a1-2d2face74178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stock_Ticker        Date    Industry                Sector  Closing_Price  \\\n",
      "0         AAPL  2024-09-01        Tech  Consumer Electronics            150   \n",
      "1        GOOGL  2024-09-01        Tech        Search Engines           2800   \n",
      "2         MSFT  2024-09-01        Tech              Software            305   \n",
      "3         TSLA  2024-09-01  Automotive            Automotive            700   \n",
      "4         AMZN  2024-09-01  E-commerce                Retail           3400   \n",
      "5         AAPL  2024-09-02        Tech  Consumer Electronics            152   \n",
      "6        GOOGL  2024-09-02        Tech        Search Engines           2820   \n",
      "7         MSFT  2024-09-02        Tech              Software            310   \n",
      "8         TSLA  2024-09-02  Automotive            Automotive            710   \n",
      "9         AMZN  2024-09-02  E-commerce                Retail           3450   \n",
      "\n",
      "     Market_Cap  P/E_Ratio  Daily_Return  \n",
      "0  2.500000e+12         30           NaN  \n",
      "1  1.800000e+12         28           NaN  \n",
      "2  2.300000e+12         35           NaN  \n",
      "3  7.000000e+11         25           NaN  \n",
      "4  1.700000e+12         70           NaN  \n",
      "5  2.600000e+12         31      0.013333  \n",
      "6  1.850000e+12         29      0.007143  \n",
      "7  2.350000e+12         34      0.016393  \n",
      "8  7.200000e+11         24      0.014286  \n",
      "9  1.750000e+12         71      0.014706  \n"
     ]
    }
   ],
   "source": [
    "#1. Calculate Daily, Weekly, or Monthly Stock Returns:\n",
    "df['Daily_Return'] = df.groupby('Stock_Ticker')['Closing_Price'].pct_change()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69bb48c9-f0a9-42c7-a9df-1786ce760520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock_Ticker                AMZN\n",
      "Date                  2024-09-02\n",
      "Industry              E-commerce\n",
      "Sector                    Retail\n",
      "Closing_Price               3450\n",
      "Market_Cap       1750000000000.0\n",
      "P/E_Ratio                     71\n",
      "Daily_Return            0.014706\n",
      "Name: 9, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Stock with the Highest Closing Price:\n",
    "highest_closing_price = df.loc[df['Closing_Price'].idxmax()]\n",
    "print(highest_closing_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e0d0d0fb-fb01-4698-a6b6-735c3705179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock_Ticker                     AAPL\n",
      "Date                       2024-09-01\n",
      "Industry                         Tech\n",
      "Sector           Consumer Electronics\n",
      "Closing_Price                     150\n",
      "Market_Cap            2500000000000.0\n",
      "P/E_Ratio                          30\n",
      "Daily_Return                      NaN\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Stock with the Lowest Closing Price:\n",
    "lowest_closing_price = df.loc[df['Closing_Price'].idxmin()]\n",
    "print(lowest_closing_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcb34105-eacd-46a1-83f9-89add6cbefc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stock_Ticker        Date    Industry                Sector  Closing_Price  \\\n",
      "0         AAPL  2024-09-01        Tech  Consumer Electronics            150   \n",
      "1        GOOGL  2024-09-01        Tech        Search Engines           2800   \n",
      "2         MSFT  2024-09-01        Tech              Software            305   \n",
      "3         TSLA  2024-09-01  Automotive            Automotive            700   \n",
      "4         AMZN  2024-09-01  E-commerce                Retail           3400   \n",
      "5         AAPL  2024-09-02        Tech  Consumer Electronics            152   \n",
      "6        GOOGL  2024-09-02        Tech        Search Engines           2820   \n",
      "7         MSFT  2024-09-02        Tech              Software            310   \n",
      "8         TSLA  2024-09-02  Automotive            Automotive            710   \n",
      "9         AMZN  2024-09-02  E-commerce                Retail           3450   \n",
      "\n",
      "     Market_Cap  P/E_Ratio  Daily_Return  2_Day_MA  \n",
      "0  2.500000e+12         30           NaN       NaN  \n",
      "1  1.800000e+12         28           NaN       NaN  \n",
      "2  2.300000e+12         35           NaN       NaN  \n",
      "3  7.000000e+11         25           NaN       NaN  \n",
      "4  1.700000e+12         70           NaN       NaN  \n",
      "5  2.600000e+12         31      0.013333     151.0  \n",
      "6  1.850000e+12         29      0.007143    2810.0  \n",
      "7  2.350000e+12         34      0.016393     307.5  \n",
      "8  7.200000e+11         24      0.014286     705.0  \n",
      "9  1.750000e+12         71      0.014706    3425.0  \n"
     ]
    }
   ],
   "source": [
    "#3 Compute Moving Averages for Stock Prices:\n",
    "df['2_Day_MA'] = df.groupby('Stock_Ticker')['Closing_Price'].rolling(window=2).mean().reset_index(0, drop=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d5df5dfa-ccfd-4b05-894a-55cc1f954cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Industry\n",
      "Automotive    24.500000\n",
      "E-commerce    70.500000\n",
      "Tech          31.166667\n",
      "Name: P/E_Ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_pe_by_industry = df.groupby('Industry')['P/E_Ratio'].mean()\n",
    "print(avg_pe_by_industry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e8c3157e-32fb-427f-b755-cbc890333be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector\n",
      "Automotive              1.420000e+12\n",
      "Consumer Electronics    5.100000e+12\n",
      "Retail                  3.450000e+12\n",
      "Search Engines          3.650000e+12\n",
      "Software                4.650000e+12\n",
      "Name: Market_Cap, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#4.Group Stock Data by Industry or Sector and Calculate Key Metrics:\n",
    "#Group by Industry and Calculate Average P/E Ratio:\n",
    "total_market_cap_by_sector = df.groupby('Sector')['Market_Cap'].sum()\n",
    "print(total_market_cap_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97af2938-e171-49cb-9926-e0e8d53f7e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector\n",
      "Automotive              1.420000e+12\n",
      "Consumer Electronics    5.100000e+12\n",
      "Retail                  3.450000e+12\n",
      "Search Engines          3.650000e+12\n",
      "Software                4.650000e+12\n",
      "Name: Market_Cap, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#4.#4.Group Stock Data by Industry or Sector and Calculate Key Metrics:\n",
    "#Group by Sector and Calculate Total Market Cap:\n",
    "total_market_cap_by_sector = df.groupby('Sector')['Market_Cap'].sum()\n",
    "print(total_market_cap_by_sector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d343af3-90a6-45e8-8742-dffdf7a0f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Customer Data Analysis\n",
    "Use Case: Analyze customer behavior or segmentation data.\n",
    "Operations:\n",
    "Group customers by location and calculate total purchases per city.\n",
    "Find the customer who made the highest number of purchases.\n",
    "Calculate the average amount spent per customer.\n",
    "Sort customers by their total purchase value. create a dataframe first and then answer these questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3677191-c5a5-4961-8dbb-773042672f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID     Name         City  Purchases  Total_Spent\n",
      "0            1    Alice     New York          5          500\n",
      "1            2      Bob  Los Angeles          8          800\n",
      "2            3  Charlie     New York         12         1200\n",
      "3            4    David      Chicago          6          600\n",
      "4            5      Eva  Los Angeles          9          900\n",
      "5            6    Frank      Chicago          5          550\n",
      "6            7    Grace     New York          7          750\n",
      "7            8   Hannah      Chicago         10         1100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample customer data\n",
    "data = {\n",
    "    'Customer_ID': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Hannah'],\n",
    "    'City': ['New York', 'Los Angeles', 'New York', 'Chicago', 'Los Angeles', 'Chicago', 'New York', 'Chicago'],\n",
    "    'Purchases': [5, 8, 12, 6, 9, 5, 7, 10],\n",
    "    'Total_Spent': [500, 800, 1200, 600, 900, 550, 750, 1100]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27228e03-f874-44b1-a2a2-01ddadd50032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\n",
      "Chicago        21\n",
      "Los Angeles    17\n",
      "New York       24\n",
      "Name: Purchases, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1 Group Customers by Location and Calculate Total Purchases per City:\n",
    "purchases_per_city = df.groupby('City')['Purchases'].sum()\n",
    "print(purchases_per_city)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e428318e-8294-49a2-94d7-aacccdac38a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_ID           3\n",
      "Name            Charlie\n",
      "City           New York\n",
      "Purchases            12\n",
      "Total_Spent        1200\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2 Find the Customer Who Made the Highest Number of Purchases:\n",
    "highest_purchases_customer = df.loc[df['Purchases'].idxmax()]\n",
    "print(highest_purchases_customer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db9ecb30-c8d9-4390-9dc1-264353f9da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800.0\n"
     ]
    }
   ],
   "source": [
    "#3 Calculate the Average Amount Spent per Customer:\n",
    "avg_spent_per_customer = df['Total_Spent'].mean()\n",
    "print(avg_spent_per_customer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ea4e476-32f0-4796-9db1-00a8ebff97a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID     Name         City  Purchases  Total_Spent\n",
      "2            3  Charlie     New York         12         1200\n",
      "7            8   Hannah      Chicago         10         1100\n",
      "4            5      Eva  Los Angeles          9          900\n",
      "1            2      Bob  Los Angeles          8          800\n",
      "6            7    Grace     New York          7          750\n",
      "3            4    David      Chicago          6          600\n",
      "5            6    Frank      Chicago          5          550\n",
      "0            1    Alice     New York          5          500\n"
     ]
    }
   ],
   "source": [
    "#4. Sort Customers by Their Total Purchase Value:\n",
    "sorted_by_total_spent = df.sort_values('Total_Spent', ascending=False)\n",
    "print(sorted_by_total_spent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb0a77-2a1f-4e62-8c0c-3f3839943c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Healthcare Data\n",
    "Use Case: Analyze patient data or medical records to gain insights.\n",
    "Operations:\n",
    "Count the number of patients per hospital or department.\n",
    "Calculate the average hospital stay per disease.\n",
    "Identify the doctor with the most patients.\n",
    "Sort patients based on age, condition severity, or treatment costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "21b1ebfb-1de9-4fcb-8d7c-35f739fc499c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID     Name       Hospital   Department     Doctor       Disease  \\\n",
      "0         101     John  City Hospital   Cardiology  Dr. Smith  Heart Attack   \n",
      "1         102     Emma  City Hospital    Neurology  Dr. Adams        Stroke   \n",
      "2         103   Sophia   Green Valley   Cardiology  Dr. Smith  Heart Attack   \n",
      "3         104  Michael   Green Valley  Orthopedics  Dr. Brown      Fracture   \n",
      "4         105   Olivia     Blue Cross    Neurology  Dr. Adams        Stroke   \n",
      "5         106    David  City Hospital  Orthopedics  Dr. Brown      Fracture   \n",
      "6         107     Liam     Blue Cross   Cardiology  Dr. Smith  Heart Attack   \n",
      "\n",
      "   Hospital_Stay_Days  Age  Condition_Severity  Treatment_Cost  \n",
      "0                   5   65                   4           15000  \n",
      "1                  12   70                   5           25000  \n",
      "2                   4   55                   3           12000  \n",
      "3                   8   45                   2            8000  \n",
      "4                  14   60                   5           26000  \n",
      "5                  10   50                   2            9500  \n",
      "6                   6   58                   3           13500  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample healthcare data\n",
    "data = {\n",
    "    'Patient_ID': [101, 102, 103, 104, 105, 106, 107],\n",
    "    'Name': ['John', 'Emma', 'Sophia', 'Michael', 'Olivia', 'David', 'Liam'],\n",
    "    'Hospital': ['City Hospital', 'City Hospital', 'Green Valley', 'Green Valley', 'Blue Cross', 'City Hospital', 'Blue Cross'],\n",
    "    'Department': ['Cardiology', 'Neurology', 'Cardiology', 'Orthopedics', 'Neurology', 'Orthopedics', 'Cardiology'],\n",
    "    'Doctor': ['Dr. Smith', 'Dr. Adams', 'Dr. Smith', 'Dr. Brown', 'Dr. Adams', 'Dr. Brown', 'Dr. Smith'],\n",
    "    'Disease': ['Heart Attack', 'Stroke', 'Heart Attack', 'Fracture', 'Stroke', 'Fracture', 'Heart Attack'],\n",
    "    'Hospital_Stay_Days': [5, 12, 4, 8, 14, 10, 6],\n",
    "    'Age': [65, 70, 55, 45, 60, 50, 58],\n",
    "    'Condition_Severity': [4, 5, 3, 2, 5, 2, 3],\n",
    "    'Treatment_Cost': [15000, 25000, 12000, 8000, 26000, 9500, 13500]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e1c7abdb-f9e3-4177-8530-6980b85e5cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital\n",
      "Blue Cross       2\n",
      "City Hospital    3\n",
      "Green Valley     2\n",
      "Name: Patient_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count the Number of Patients per Hospital \n",
    "patients_per_hospital = df.groupby('Hospital')['Patient_ID'].count()\n",
    "print(patients_per_hospital)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c177492f-c2b5-4220-bce7-2e33a7e0bf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department\n",
      "Cardiology     3\n",
      "Neurology      2\n",
      "Orthopedics    2\n",
      "Name: Patient_ID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count the Number of Patients per Department\n",
    "patients_per_department = df.groupby('Department')['Patient_ID'].count()\n",
    "print(patients_per_department)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eab0aae3-d43f-49f7-8680-7a2e6733c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease\n",
      "Fracture         9.0\n",
      "Heart Attack     5.0\n",
      "Stroke          13.0\n",
      "Name: Hospital_Stay_Days, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#2. Calculate the Average Hospital Stay per Disease:\n",
    "avg_stay_per_disease = df.groupby('Disease')['Hospital_Stay_Days'].mean()\n",
    "print(avg_stay_per_disease)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "961c61d7-4615-4058-a4bd-c3601d8bdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Smith\n"
     ]
    }
   ],
   "source": [
    "#3.Identify the Doctor with the Most Patients:\n",
    "doctor_with_most_patients = df.groupby('Doctor')['Patient_ID'].count().idxmax()\n",
    "print(doctor_with_most_patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d0a1cb7-a290-440d-aeef-56cf28a6403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID     Name       Hospital   Department     Doctor       Disease  \\\n",
      "3         104  Michael   Green Valley  Orthopedics  Dr. Brown      Fracture   \n",
      "5         106    David  City Hospital  Orthopedics  Dr. Brown      Fracture   \n",
      "2         103   Sophia   Green Valley   Cardiology  Dr. Smith  Heart Attack   \n",
      "6         107     Liam     Blue Cross   Cardiology  Dr. Smith  Heart Attack   \n",
      "4         105   Olivia     Blue Cross    Neurology  Dr. Adams        Stroke   \n",
      "0         101     John  City Hospital   Cardiology  Dr. Smith  Heart Attack   \n",
      "1         102     Emma  City Hospital    Neurology  Dr. Adams        Stroke   \n",
      "\n",
      "   Hospital_Stay_Days  Age  Condition_Severity  Treatment_Cost  \n",
      "3                   8   45                   2            8000  \n",
      "5                  10   50                   2            9500  \n",
      "2                   4   55                   3           12000  \n",
      "6                   6   58                   3           13500  \n",
      "4                  14   60                   5           26000  \n",
      "0                   5   65                   4           15000  \n",
      "1                  12   70                   5           25000  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Patients Based on Age:\n",
    "sorted_by_age = df.sort_values('Age', ascending=True)\n",
    "print(sorted_by_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b3264d57-f656-462c-a606-9570161b88f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID     Name       Hospital   Department     Doctor       Disease  \\\n",
      "1         102     Emma  City Hospital    Neurology  Dr. Adams        Stroke   \n",
      "4         105   Olivia     Blue Cross    Neurology  Dr. Adams        Stroke   \n",
      "0         101     John  City Hospital   Cardiology  Dr. Smith  Heart Attack   \n",
      "2         103   Sophia   Green Valley   Cardiology  Dr. Smith  Heart Attack   \n",
      "6         107     Liam     Blue Cross   Cardiology  Dr. Smith  Heart Attack   \n",
      "3         104  Michael   Green Valley  Orthopedics  Dr. Brown      Fracture   \n",
      "5         106    David  City Hospital  Orthopedics  Dr. Brown      Fracture   \n",
      "\n",
      "   Hospital_Stay_Days  Age  Condition_Severity  Treatment_Cost  \n",
      "1                  12   70                   5           25000  \n",
      "4                  14   60                   5           26000  \n",
      "0                   5   65                   4           15000  \n",
      "2                   4   55                   3           12000  \n",
      "6                   6   58                   3           13500  \n",
      "3                   8   45                   2            8000  \n",
      "5                  10   50                   2            9500  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Patients Based on Condition Severity:\n",
    "sorted_by_severity = df.sort_values('Condition_Severity', ascending=False)\n",
    "print(sorted_by_severity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d8f9f79d-3b91-4fb5-94f2-42359747752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Patient_ID     Name       Hospital   Department     Doctor       Disease  \\\n",
      "4         105   Olivia     Blue Cross    Neurology  Dr. Adams        Stroke   \n",
      "1         102     Emma  City Hospital    Neurology  Dr. Adams        Stroke   \n",
      "0         101     John  City Hospital   Cardiology  Dr. Smith  Heart Attack   \n",
      "6         107     Liam     Blue Cross   Cardiology  Dr. Smith  Heart Attack   \n",
      "2         103   Sophia   Green Valley   Cardiology  Dr. Smith  Heart Attack   \n",
      "5         106    David  City Hospital  Orthopedics  Dr. Brown      Fracture   \n",
      "3         104  Michael   Green Valley  Orthopedics  Dr. Brown      Fracture   \n",
      "\n",
      "   Hospital_Stay_Days  Age  Condition_Severity  Treatment_Cost  \n",
      "4                  14   60                   5           26000  \n",
      "1                  12   70                   5           25000  \n",
      "0                   5   65                   4           15000  \n",
      "6                   6   58                   3           13500  \n",
      "2                   4   55                   3           12000  \n",
      "5                  10   50                   2            9500  \n",
      "3                   8   45                   2            8000  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Patients Based on Treatment Costs:\n",
    "sorted_by_cost = df.sort_values('Treatment_Cost', ascending=False)\n",
    "print(sorted_by_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fc5cab-28b7-4147-babe-998f1a58934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. E-commerce Data Analysis\n",
    "Use Case: Analyze online sales, product views, and customer engagement data.\n",
    "Operations:\n",
    "Count total orders per product category.\n",
    "Find the most viewed or most purchased product.\n",
    "Calculate the average cart value of customers.\n",
    "Sort products by total sales or views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b882b187-e08b-43d5-ba73-13b75426d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product_ID Product_Name     Category  Views  Orders  Price  Customer_ID  \\\n",
      "0        1001       Laptop  Electronics   1200     300   1500          101   \n",
      "1        1002   Smartphone  Electronics   3500     500    700          102   \n",
      "2        1003   Headphones  Accessories    800     150    200          103   \n",
      "3        1004   Smartwatch    Wearables    950     180    250          104   \n",
      "4        1005       Tablet  Electronics   2300     400    500          105   \n",
      "5        1006       Camera  Photography   1200     250   1200          106   \n",
      "\n",
      "   Cart_Value  \n",
      "0        1600  \n",
      "1         900  \n",
      "2         200  \n",
      "3         260  \n",
      "4         550  \n",
      "5        1300  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample e-commerce data\n",
    "data = {\n",
    "    'Product_ID': [1001, 1002, 1003, 1004, 1005, 1006],\n",
    "    'Product_Name': ['Laptop', 'Smartphone', 'Headphones', 'Smartwatch', 'Tablet', 'Camera'],\n",
    "    'Category': ['Electronics', 'Electronics', 'Accessories', 'Wearables', 'Electronics', 'Photography'],\n",
    "    'Views': [1200, 3500, 800, 950, 2300, 1200],\n",
    "    'Orders': [300, 500, 150, 180, 400, 250],\n",
    "    'Price': [1500, 700, 200, 250, 500, 1200],\n",
    "    'Customer_ID': [101, 102, 103, 104, 105, 106],\n",
    "    'Cart_Value': [1600, 900, 200, 260, 550, 1300]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "732ef7de-a066-41fe-b494-b2c2cffb7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Accessories     150\n",
      "Electronics    1200\n",
      "Photography     250\n",
      "Wearables       180\n",
      "Name: Orders, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.Count Total Orders per Product Category:\n",
    "orders_per_category = df.groupby('Category')['Orders'].sum()\n",
    "print(orders_per_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b559e67a-3aae-41d7-8b04-a0553c571685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_ID             1002\n",
      "Product_Name     Smartphone\n",
      "Category        Electronics\n",
      "Views                  3500\n",
      "Orders                  500\n",
      "Price                   700\n",
      "Customer_ID             102\n",
      "Cart_Value              900\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Most Viewed Product:\n",
    "most_viewed_product = df.loc[df['Views'].idxmax()]\n",
    "print(most_viewed_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9f8b40bf-2c58-44bf-9c74-34d4c796a7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_ID             1002\n",
      "Product_Name     Smartphone\n",
      "Category        Electronics\n",
      "Views                  3500\n",
      "Orders                  500\n",
      "Price                   700\n",
      "Customer_ID             102\n",
      "Cart_Value              900\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Most Purchased Product:\n",
    "most_purchased_product = df.loc[df['Orders'].idxmax()]\n",
    "print(most_purchased_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "345b3a11-8493-45dd-8162-301da520e314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801.6666666666666\n"
     ]
    }
   ],
   "source": [
    "#3. Calculate the Average Cart Value of Customers:\n",
    "avg_cart_value = df['Cart_Value'].mean()\n",
    "print(avg_cart_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b3fb0c5d-f424-4ba3-b890-c4b9d2dc0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product_ID Product_Name     Category  Views  Orders  Price  Customer_ID  \\\n",
      "1        1002   Smartphone  Electronics   3500     500    700          102   \n",
      "4        1005       Tablet  Electronics   2300     400    500          105   \n",
      "0        1001       Laptop  Electronics   1200     300   1500          101   \n",
      "5        1006       Camera  Photography   1200     250   1200          106   \n",
      "3        1004   Smartwatch    Wearables    950     180    250          104   \n",
      "2        1003   Headphones  Accessories    800     150    200          103   \n",
      "\n",
      "   Cart_Value  \n",
      "1         900  \n",
      "4         550  \n",
      "0        1600  \n",
      "5        1300  \n",
      "3         260  \n",
      "2         200  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Products by Total Sales:\n",
    "sorted_by_orders = df.sort_values('Orders', ascending=False)\n",
    "print(sorted_by_orders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "26805e9a-0e02-45e9-b39a-3013c246ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product_ID Product_Name     Category  Views  Orders  Price  Customer_ID  \\\n",
      "1        1002   Smartphone  Electronics   3500     500    700          102   \n",
      "4        1005       Tablet  Electronics   2300     400    500          105   \n",
      "0        1001       Laptop  Electronics   1200     300   1500          101   \n",
      "5        1006       Camera  Photography   1200     250   1200          106   \n",
      "3        1004   Smartwatch    Wearables    950     180    250          104   \n",
      "2        1003   Headphones  Accessories    800     150    200          103   \n",
      "\n",
      "   Cart_Value  \n",
      "1         900  \n",
      "4         550  \n",
      "0        1600  \n",
      "5        1300  \n",
      "3         260  \n",
      "2         200  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort by Views:\n",
    "sorted_by_views = df.sort_values('Views', ascending=False)\n",
    "print(sorted_by_views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fcba6-cc7c-4088-9323-73c5edb49662",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Sports Data Analytics\n",
    "Use Case: Analyze player or team performance data.\n",
    "Operations:\n",
    "Count the number of goals per team or player.\n",
    "Calculate the average points scored per game.\n",
    "Find the player with the highest score in a season.\n",
    "Sort players or teams by win/loss ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7aa16d33-a71c-414a-b87a-5f3a4119801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Player_ID Player_Name    Team  Goals  Points  Games_Played  Wins  Losses\n",
      "0          1        John  Team A     20      50            10     8       2\n",
      "1          2        Emma  Team A     15      40            12     7       5\n",
      "2          3      Sophia  Team B     25      60            14    10       4\n",
      "3          4     Michael  Team B     22      55            13     9       3\n",
      "4          5      Olivia  Team C     18      45            11     6       5\n",
      "5          6       David  Team C     30      70            15    12       3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample sports data\n",
    "data = {\n",
    "    'Player_ID': [1, 2, 3, 4, 5, 6],\n",
    "    'Player_Name': ['John', 'Emma', 'Sophia', 'Michael', 'Olivia', 'David'],\n",
    "    'Team': ['Team A', 'Team A', 'Team B', 'Team B', 'Team C', 'Team C'],\n",
    "    'Goals': [20, 15, 25, 22, 18, 30],\n",
    "    'Points': [50, 40, 60, 55, 45, 70],\n",
    "    'Games_Played': [10, 12, 14, 13, 11, 15],\n",
    "    'Wins': [8, 7, 10, 9, 6, 12],\n",
    "    'Losses': [2, 5, 4, 3, 5, 3]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0c445544-2081-4686-8dca-3d36c7d5bd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team\n",
      "Team A    35\n",
      "Team B    47\n",
      "Team C    48\n",
      "Name: Goals, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count the Number of Goals per Team:\n",
    "goals_per_team = df.groupby('Team')['Goals'].sum()\n",
    "print(goals_per_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c53d2f6c-0c78-489c-b187-4048cdbd3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player_Name\n",
      "David      30\n",
      "Emma       15\n",
      "John       20\n",
      "Michael    22\n",
      "Olivia     18\n",
      "Sophia     25\n",
      "Name: Goals, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count the Number of Goals per Player:\n",
    "goals_per_player = df.groupby('Player_Name')['Goals'].sum()\n",
    "print(goals_per_player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "41f7a009-93c9-413a-913d-357043836c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Player_Name  Average_Points_Per_Game\n",
      "0        John                 5.000000\n",
      "1        Emma                 3.333333\n",
      "2      Sophia                 4.285714\n",
      "3     Michael                 4.230769\n",
      "4      Olivia                 4.090909\n",
      "5       David                 4.666667\n"
     ]
    }
   ],
   "source": [
    "#2. Calculate the Average Points Scored per Game:\n",
    "df['Average_Points_Per_Game'] = df['Points'] / df['Games_Played']\n",
    "avg_points_per_game = df[['Player_Name', 'Average_Points_Per_Game']]\n",
    "print(avg_points_per_game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "53dd907e-9283-4829-b372-bdf4017ae2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player_ID                         6\n",
      "Player_Name                   David\n",
      "Team                         Team C\n",
      "Goals                            30\n",
      "Points                           70\n",
      "Games_Played                     15\n",
      "Wins                             12\n",
      "Losses                            3\n",
      "Average_Points_Per_Game    4.666667\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#3. Find the Player with the Highest Score in a Season:\n",
    "highest_score_player = df.loc[df['Points'].idxmax()]\n",
    "print(highest_score_player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06f1f0be-4508-4ece-b709-7b6ba674d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Player_ID Player_Name    Team  Goals  Points  Games_Played  Wins  Losses  \\\n",
      "0          1        John  Team A     20      50            10     8       2   \n",
      "5          6       David  Team C     30      70            15    12       3   \n",
      "3          4     Michael  Team B     22      55            13     9       3   \n",
      "2          3      Sophia  Team B     25      60            14    10       4   \n",
      "1          2        Emma  Team A     15      40            12     7       5   \n",
      "4          5      Olivia  Team C     18      45            11     6       5   \n",
      "\n",
      "   Average_Points_Per_Game  Win_Loss_Ratio  \n",
      "0                 5.000000             4.0  \n",
      "5                 4.666667             4.0  \n",
      "3                 4.230769             3.0  \n",
      "2                 4.285714             2.5  \n",
      "1                 3.333333             1.4  \n",
      "4                 4.090909             1.2  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Players or Teams by Win/Loss Ratios:\n",
    "#By player\n",
    "df['Win_Loss_Ratio'] = df['Wins'] / df['Losses']\n",
    "sorted_by_win_loss_ratio = df.sort_values('Win_Loss_Ratio', ascending=False)\n",
    "print(sorted_by_win_loss_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f464ecc9-d4ea-4c0f-a590-6eea1bd3fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Wins  Losses  Win_Loss_Ratio\n",
      "Team                                \n",
      "Team B    19       7        2.714286\n",
      "Team C    18       8        2.250000\n",
      "Team A    15       7        2.142857\n"
     ]
    }
   ],
   "source": [
    "#4. Sort Players or Teams by Win/Loss Ratios:\n",
    "#By team\n",
    "team_stats = df.groupby('Team').agg({'Wins': 'sum', 'Losses': 'sum'})\n",
    "team_stats['Win_Loss_Ratio'] = team_stats['Wins'] / team_stats['Losses']\n",
    "sorted_by_team_win_loss_ratio = team_stats.sort_values('Win_Loss_Ratio', ascending=False)\n",
    "print(sorted_by_team_win_loss_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8cacb-aeec-457c-a069-60819627ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Survey Data Analysis\n",
    "Use Case: Analyze responses from customer or employee surveys.\n",
    "Operations:\n",
    "Count responses per survey category (e.g., satisfaction, experience).\n",
    "Calculate the average rating for each question.\n",
    "Find the question with the most positive or negative responses.\n",
    "Sort responses by rating or demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "94aca4c3-d56d-4fd9-8873-2efb750b7557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent_ID      Category         Question  Rating Demographic_Group\n",
      "0              1  Satisfaction  Service Quality       4           Group A\n",
      "1              2    Experience  Product Quality       3           Group B\n",
      "2              3  Satisfaction  Service Quality       5           Group A\n",
      "3              4    Experience  Product Quality       4           Group B\n",
      "4              5  Satisfaction  Service Quality       2           Group A\n",
      "5              6    Experience  Product Quality       5           Group C\n",
      "6              7  Satisfaction  Service Quality       3           Group B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample survey data\n",
    "data = {\n",
    "    'Respondent_ID': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'Category': ['Satisfaction', 'Experience', 'Satisfaction', 'Experience', 'Satisfaction', 'Experience', 'Satisfaction'],\n",
    "    'Question': ['Service Quality', 'Product Quality', 'Service Quality', 'Product Quality', 'Service Quality', 'Product Quality', 'Service Quality'],\n",
    "    'Rating': [4, 3, 5, 4, 2, 5, 3],\n",
    "    'Demographic_Group': ['Group A', 'Group B', 'Group A', 'Group B', 'Group A', 'Group C', 'Group B']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3485afc1-c555-481b-9a6b-3a1090ff12a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Satisfaction    4\n",
      "Experience      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count Responses per Survey Category:\n",
    "responses_per_category = df['Category'].value_counts()\n",
    "print(responses_per_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4239da2d-304d-43d0-a998-b6e725fd2dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question\n",
      "Product Quality    4.0\n",
      "Service Quality    3.5\n",
      "Name: Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#2. Calculate the Average Rating for Each Question:\n",
    "avg_rating_per_question = df.groupby('Question')['Rating'].mean()\n",
    "print(avg_rating_per_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "40d5acb3-73e9-460a-b73e-ce6ea386bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Quality\n"
     ]
    }
   ],
   "source": [
    "#3. Find the Question with the Most Positive Responses:\n",
    "most_positive_question = df.groupby('Question')['Rating'].mean().idxmax()\n",
    "print(most_positive_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "054ec092-f9f6-48d4-8cca-fb869a7cc8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Quality\n"
     ]
    }
   ],
   "source": [
    "#3. Find the Question with the Most Negative Responses:\n",
    "most_negative_question = df.groupby('Question')['Rating'].mean().idxmin()\n",
    "print(most_negative_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "24b2d87d-ef79-4b7e-b0d3-29ad3556940e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent_ID      Category         Question  Rating Demographic_Group\n",
      "2              3  Satisfaction  Service Quality       5           Group A\n",
      "5              6    Experience  Product Quality       5           Group C\n",
      "0              1  Satisfaction  Service Quality       4           Group A\n",
      "3              4    Experience  Product Quality       4           Group B\n",
      "1              2    Experience  Product Quality       3           Group B\n",
      "6              7  Satisfaction  Service Quality       3           Group B\n",
      "4              5  Satisfaction  Service Quality       2           Group A\n"
     ]
    }
   ],
   "source": [
    "#4. Sort Responses by Rating:\n",
    "sorted_by_rating = df.sort_values('Rating', ascending=False)\n",
    "print(sorted_by_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "26488983-379f-41a1-b8e8-94083ac3ab00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Respondent_ID      Category         Question  Rating Demographic_Group\n",
      "0              1  Satisfaction  Service Quality       4           Group A\n",
      "2              3  Satisfaction  Service Quality       5           Group A\n",
      "4              5  Satisfaction  Service Quality       2           Group A\n",
      "1              2    Experience  Product Quality       3           Group B\n",
      "3              4    Experience  Product Quality       4           Group B\n",
      "6              7  Satisfaction  Service Quality       3           Group B\n",
      "5              6    Experience  Product Quality       5           Group C\n"
     ]
    }
   ],
   "source": [
    "#4. Sort Responses by Demographic Group:\n",
    "sorted_by_demographic = df.sort_values('Demographic_Group')\n",
    "print(sorted_by_demographic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e2de55-e247-46f3-8faa-229ca1e0ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. IoT and Sensor Data\n",
    "Use Case: Manage time series data from sensors for predictive maintenance or monitoring.\n",
    "Operations:\n",
    "Analyze average temperature, pressure, or humidity readings.\n",
    "Identify anomalies in the sensor data over time.\n",
    "Group sensor readings by location or machine and calculate metrics.\n",
    "Sort sensor data by timestamp or severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "621fbf7d-73c8-4b51-8561-837a980d9a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sensor_ID   Location    Machine           Timestamp  Temperature  Pressure  \\\n",
      "0          1  Factory A  Machine 1 2024-09-01 08:00:00           70        30   \n",
      "1          2  Factory A  Machine 2 2024-09-01 09:00:00           72        32   \n",
      "2          3  Factory B  Machine 1 2024-09-01 08:00:00           68        29   \n",
      "3          4  Factory B  Machine 2 2024-09-01 09:00:00           73        31   \n",
      "4          5  Factory A  Machine 3 2024-09-01 08:00:00           71        30   \n",
      "5          6  Factory C  Machine 1 2024-09-01 08:00:00           75        33   \n",
      "6          7  Factory B  Machine 2 2024-09-01 09:00:00           69        28   \n",
      "7          8  Factory C  Machine 3 2024-09-01 10:00:00           74        34   \n",
      "\n",
      "   Humidity  \n",
      "0        45  \n",
      "1        50  \n",
      "2        42  \n",
      "3        48  \n",
      "4        46  \n",
      "5        52  \n",
      "6        41  \n",
      "7        49  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample IoT sensor data\n",
    "data = {\n",
    "    'Sensor_ID': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'Location': ['Factory A', 'Factory A', 'Factory B', 'Factory B', 'Factory A', 'Factory C', 'Factory B', 'Factory C'],\n",
    "    'Machine': ['Machine 1', 'Machine 2', 'Machine 1', 'Machine 2', 'Machine 3', 'Machine 1', 'Machine 2', 'Machine 3'],\n",
    "    'Timestamp': pd.to_datetime(['2024-09-01 08:00', '2024-09-01 09:00', '2024-09-01 08:00', '2024-09-01 09:00', '2024-09-01 08:00',\n",
    "                                 '2024-09-01 08:00', '2024-09-01 09:00', '2024-09-01 10:00']),\n",
    "    'Temperature': [70, 72, 68, 73, 71, 75, 69, 74],\n",
    "    'Pressure': [30, 32, 29, 31, 30, 33, 28, 34],\n",
    "    'Humidity': [45, 50, 42, 48, 46, 52, 41, 49]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4f920117-89e8-4591-bcb7-844fedd6774a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Temperature: 71.5\n",
      "Average Pressure: 30.875\n",
      "Average Humidity: 46.625\n"
     ]
    }
   ],
   "source": [
    "#1. Analyze Average Temperature, Pressure, or Humidity Readings:\n",
    "avg_temperature = df['Temperature'].mean()\n",
    "avg_pressure = df['Pressure'].mean()\n",
    "avg_humidity = df['Humidity'].mean()\n",
    "\n",
    "print(f'Average Temperature: {avg_temperature}')\n",
    "print(f'Average Pressure: {avg_pressure}')\n",
    "print(f'Average Humidity: {avg_humidity}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "58d35504-5e48-49db-a12b-bc7fb18b525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Sensor_ID, Location, Machine, Timestamp, Temperature, Pressure, Humidity, Temp_Z_Score, Pressure_Z_Score, Humidity_Z_Score]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#2. Identify Anomalies in the Sensor Data Over Time:\n",
    "from scipy import stats\n",
    "\n",
    "# Compute z-scores\n",
    "df['Temp_Z_Score'] = stats.zscore(df['Temperature'])\n",
    "df['Pressure_Z_Score'] = stats.zscore(df['Pressure'])\n",
    "df['Humidity_Z_Score'] = stats.zscore(df['Humidity'])\n",
    "\n",
    "# Identify anomalies (z-score > 2 or < -2)\n",
    "anomalies = df[(df['Temp_Z_Score'].abs() > 2) | (df['Pressure_Z_Score'].abs() > 2) | (df['Humidity_Z_Score'].abs() > 2)]\n",
    "print(anomalies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0f5e62b7-caf2-4fe9-b44c-de40069447a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Temperature   Pressure   Humidity\n",
      "Location                                    \n",
      "Factory A         71.0  30.666667  47.000000\n",
      "Factory B         70.0  29.333333  43.666667\n",
      "Factory C         74.5  33.500000  50.500000\n"
     ]
    }
   ],
   "source": [
    "#3.Group by Location and Calculate Average Temperature, Pressure, Humidity:\n",
    "metrics_by_location = df.groupby('Location').agg({\n",
    "    'Temperature': 'mean',\n",
    "    'Pressure': 'mean',\n",
    "    'Humidity': 'mean'\n",
    "})\n",
    "print(metrics_by_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c53cb72b-8522-454a-ae19-c07071812414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Temperature   Pressure   Humidity\n",
      "Machine                                     \n",
      "Machine 1    71.000000  30.666667  46.333333\n",
      "Machine 2    71.333333  30.333333  46.333333\n",
      "Machine 3    72.500000  32.000000  47.500000\n"
     ]
    }
   ],
   "source": [
    "#3. Group by Machine and Calculate Average Temperature, Pressure, Humidity:\n",
    "metrics_by_machine = df.groupby('Machine').agg({\n",
    "    'Temperature': 'mean',\n",
    "    'Pressure': 'mean',\n",
    "    'Humidity': 'mean'\n",
    "})\n",
    "print(metrics_by_machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "130005ca-25ed-47c2-87ad-e224c723a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sensor_ID   Location    Machine           Timestamp  Temperature  Pressure  \\\n",
      "0          1  Factory A  Machine 1 2024-09-01 08:00:00           70        30   \n",
      "2          3  Factory B  Machine 1 2024-09-01 08:00:00           68        29   \n",
      "4          5  Factory A  Machine 3 2024-09-01 08:00:00           71        30   \n",
      "5          6  Factory C  Machine 1 2024-09-01 08:00:00           75        33   \n",
      "1          2  Factory A  Machine 2 2024-09-01 09:00:00           72        32   \n",
      "3          4  Factory B  Machine 2 2024-09-01 09:00:00           73        31   \n",
      "6          7  Factory B  Machine 2 2024-09-01 09:00:00           69        28   \n",
      "7          8  Factory C  Machine 3 2024-09-01 10:00:00           74        34   \n",
      "\n",
      "   Humidity  Temp_Z_Score  Pressure_Z_Score  Humidity_Z_Score  \n",
      "0        45     -0.654654         -0.460566         -0.450965  \n",
      "2        42     -1.527525         -0.986928         -1.283516  \n",
      "4        46     -0.218218         -0.460566         -0.173448  \n",
      "5        52      1.527525          1.118518          1.491653  \n",
      "1        50      0.218218          0.592157          0.936620  \n",
      "3        48      0.654654          0.065795          0.381586  \n",
      "6        41     -1.091089         -1.513289         -1.561033  \n",
      "7        49      1.091089          1.644879          0.659103  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Sensor Data by Timestamp\n",
    "sorted_by_timestamp = df.sort_values('Timestamp')\n",
    "print(sorted_by_timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "213e1edd-074e-421b-8076-d69ffd0e5149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sensor_ID   Location    Machine           Timestamp  Temperature  Pressure  \\\n",
      "5          6  Factory C  Machine 1 2024-09-01 08:00:00           75        33   \n",
      "7          8  Factory C  Machine 3 2024-09-01 10:00:00           74        34   \n",
      "3          4  Factory B  Machine 2 2024-09-01 09:00:00           73        31   \n",
      "1          2  Factory A  Machine 2 2024-09-01 09:00:00           72        32   \n",
      "4          5  Factory A  Machine 3 2024-09-01 08:00:00           71        30   \n",
      "0          1  Factory A  Machine 1 2024-09-01 08:00:00           70        30   \n",
      "6          7  Factory B  Machine 2 2024-09-01 09:00:00           69        28   \n",
      "2          3  Factory B  Machine 1 2024-09-01 08:00:00           68        29   \n",
      "\n",
      "   Humidity  Temp_Z_Score  Pressure_Z_Score  Humidity_Z_Score  \n",
      "5        52      1.527525          1.118518          1.491653  \n",
      "7        49      1.091089          1.644879          0.659103  \n",
      "3        48      0.654654          0.065795          0.381586  \n",
      "1        50      0.218218          0.592157          0.936620  \n",
      "4        46     -0.218218         -0.460566         -0.173448  \n",
      "0        45     -0.654654         -0.460566         -0.450965  \n",
      "6        41     -1.091089         -1.513289         -1.561033  \n",
      "2        42     -1.527525         -0.986928         -1.283516  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Sensor Data by Severity:\n",
    "sorted_by_severity = df.sort_values('Temperature', ascending=False)\n",
    "print(sorted_by_severity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8e5a55-8e64-47a9-a0c2-80659019682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Social Media Analysis\n",
    "Use Case: Perform analysis on social media posts, hashtags, or engagement metrics.\n",
    "Operations:\n",
    "Count total likes, shares, or comments per post.\n",
    "Find the post with the highest engagement.\n",
    "Calculate average engagement per hashtag or user.\n",
    "Sort posts based on date, likes, or shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "478c555c-f964-4c9f-8d18-41f5a61fba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post_ID  User_ID       Date      Hashtags  Likes  Shares  Comments\n",
      "0      101        1 2024-09-01          #fun    150      20        10\n",
      "1      102        2 2024-09-02         #life    200      25        12\n",
      "2      103        1 2024-09-03  #fun #summer    300      40        15\n",
      "3      104        3 2024-09-01         #life    180      30         8\n",
      "4      105        2 2024-09-04       #summer    220      35        14\n",
      "5      106        1 2024-09-02          #fun    160      22        11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample social media data\n",
    "data = {\n",
    "    'Post_ID': [101, 102, 103, 104, 105, 106],\n",
    "    'User_ID': [1, 2, 1, 3, 2, 1],\n",
    "    'Date': pd.to_datetime(['2024-09-01', '2024-09-02', '2024-09-03', '2024-09-01', '2024-09-04', '2024-09-02']),\n",
    "    'Hashtags': ['#fun', '#life', '#fun #summer', '#life', '#summer', '#fun'],\n",
    "    'Likes': [150, 200, 300, 180, 220, 160],\n",
    "    'Shares': [20, 25, 40, 30, 35, 22],\n",
    "    'Comments': [10, 12, 15, 8, 14, 11]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "38a1253d-1007-45d2-b04e-14efd226668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post_ID  Total_Engagement\n",
      "0      101               180\n",
      "1      102               237\n",
      "2      103               355\n",
      "3      104               218\n",
      "4      105               269\n",
      "5      106               193\n"
     ]
    }
   ],
   "source": [
    "#1.Count Total Likes, Shares, or Comments per Post:\n",
    "df['Total_Engagement'] = df['Likes'] + df['Shares'] + df['Comments']\n",
    "print(df[['Post_ID', 'Total_Engagement']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "36ec19f3-0d83-4b46-b76b-c1f03a276fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post_ID                             103\n",
      "User_ID                               1\n",
      "Date                2024-09-03 00:00:00\n",
      "Hashtags                   #fun #summer\n",
      "Likes                               300\n",
      "Shares                               40\n",
      "Comments                             15\n",
      "Total_Engagement                    355\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2.Find the Post with the Highest Engagement:\n",
    "highest_engagement_post = df.loc[df['Total_Engagement'].idxmax()]\n",
    "print(highest_engagement_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "49a8903e-5d94-49d9-891a-dac11391b313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashtags\n",
      "#fun       242.666667\n",
      "#life      227.500000\n",
      "#summer    312.000000\n",
      "Name: Total_Engagement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#3. Calculate Average Engagement per Hashtag\n",
    "df_exploded = df.assign(Hashtags=df['Hashtags'].str.split()).explode('Hashtags')\n",
    "avg_engagement_per_hashtag = df_exploded.groupby('Hashtags')['Total_Engagement'].mean()\n",
    "print(avg_engagement_per_hashtag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1a22c890-a706-4d5c-83f2-44655f14a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID\n",
      "1    242.666667\n",
      "2    253.000000\n",
      "3    218.000000\n",
      "Name: Total_Engagement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#3. Calculate Average Engagement per User:\n",
    "avg_engagement_per_user = df.groupby('User_ID')['Total_Engagement'].mean()\n",
    "print(avg_engagement_per_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "dbf4c1c9-3238-45f8-aa99-bbfe3a7b8ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post_ID  User_ID       Date      Hashtags  Likes  Shares  Comments  \\\n",
      "0      101        1 2024-09-01          #fun    150      20        10   \n",
      "3      104        3 2024-09-01         #life    180      30         8   \n",
      "1      102        2 2024-09-02         #life    200      25        12   \n",
      "5      106        1 2024-09-02          #fun    160      22        11   \n",
      "2      103        1 2024-09-03  #fun #summer    300      40        15   \n",
      "4      105        2 2024-09-04       #summer    220      35        14   \n",
      "\n",
      "   Total_Engagement  \n",
      "0               180  \n",
      "3               218  \n",
      "1               237  \n",
      "5               193  \n",
      "2               355  \n",
      "4               269  \n"
     ]
    }
   ],
   "source": [
    "#4.Sort Posts Based on Date\n",
    "sorted_by_date = df.sort_values('Date')\n",
    "print(sorted_by_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "1e33321a-8636-4e44-81ba-f0fa5d3aad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post_ID  User_ID       Date      Hashtags  Likes  Shares  Comments  \\\n",
      "2      103        1 2024-09-03  #fun #summer    300      40        15   \n",
      "4      105        2 2024-09-04       #summer    220      35        14   \n",
      "1      102        2 2024-09-02         #life    200      25        12   \n",
      "3      104        3 2024-09-01         #life    180      30         8   \n",
      "5      106        1 2024-09-02          #fun    160      22        11   \n",
      "0      101        1 2024-09-01          #fun    150      20        10   \n",
      "\n",
      "   Total_Engagement  \n",
      "2               355  \n",
      "4               269  \n",
      "1               237  \n",
      "3               218  \n",
      "5               193  \n",
      "0               180  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Posts Based on Likes:\n",
    "sorted_by_likes = df.sort_values('Likes', ascending=False)\n",
    "print(sorted_by_likes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "837f1207-adc7-45e2-9f68-6e2192506190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Post_ID  User_ID       Date      Hashtags  Likes  Shares  Comments  \\\n",
      "2      103        1 2024-09-03  #fun #summer    300      40        15   \n",
      "4      105        2 2024-09-04       #summer    220      35        14   \n",
      "3      104        3 2024-09-01         #life    180      30         8   \n",
      "1      102        2 2024-09-02         #life    200      25        12   \n",
      "5      106        1 2024-09-02          #fun    160      22        11   \n",
      "0      101        1 2024-09-01          #fun    150      20        10   \n",
      "\n",
      "   Total_Engagement  \n",
      "2               355  \n",
      "4               269  \n",
      "3               218  \n",
      "1               237  \n",
      "5               193  \n",
      "0               180  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Posts Based on Shares:\n",
    "sorted_by_shares = df.sort_values('Shares', ascending=False)\n",
    "print(sorted_by_shares)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562a211-d61f-48d5-9538-0e9e45d90c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Educational Data Analysis\n",
    "Use Case: Analyze student performance, attendance, or academic records.\n",
    "Operations:\n",
    "Count the number of students per grade or subject.\n",
    "Find the student with the highest overall GPA.\n",
    "Calculate average scores per subject.\n",
    "Sort students based on their grades or attendance rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "65b51cbc-d00e-4424-9fca-c6754cad21ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student_ID     Name Grade  Subject  Score  GPA  Attendance_Rate\n",
      "0           1    Alice     A     Math     90  3.9               95\n",
      "1           2      Bob     B  Science     80  3.4               88\n",
      "2           3  Charlie     A     Math     85  3.7               90\n",
      "3           4    David     C  English     70  2.8               85\n",
      "4           5      Eva     B  Science     88  3.5               92\n",
      "5           6    Frank     A     Math     95  3.8               96\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample educational data\n",
    "data = {\n",
    "    'Student_ID': [1, 2, 3, 4, 5, 6],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank'],\n",
    "    'Grade': ['A', 'B', 'A', 'C', 'B', 'A'],\n",
    "    'Subject': ['Math', 'Science', 'Math', 'English', 'Science', 'Math'],\n",
    "    'Score': [90, 80, 85, 70, 88, 95],\n",
    "    'GPA': [3.9, 3.4, 3.7, 2.8, 3.5, 3.8],\n",
    "    'Attendance_Rate': [95, 88, 90, 85, 92, 96]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "323912bc-062f-4240-9748-f2099ac3573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade\n",
      "A    3\n",
      "B    2\n",
      "C    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count the Number of Students per Grade:\n",
    "students_per_grade = df['Grade'].value_counts()\n",
    "print(students_per_grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fb838c04-1d8d-4e60-8191-4f5365a604a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "Math       3\n",
      "Science    2\n",
      "English    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count the Number of Students per Subject:\n",
    "students_per_subject = df['Subject'].value_counts()\n",
    "print(students_per_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "03748d07-9467-495e-aac4-a46874ee45e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student_ID             1\n",
      "Name               Alice\n",
      "Grade                  A\n",
      "Subject             Math\n",
      "Score                 90\n",
      "GPA                  3.9\n",
      "Attendance_Rate       95\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Student with the Highest Overall GPA:\n",
    "highest_gpa_student = df.loc[df['GPA'].idxmax()]\n",
    "print(highest_gpa_student)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f6acbdb2-8c91-48b3-a34d-09420b8792a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject\n",
      "English    70.0\n",
      "Math       90.0\n",
      "Science    84.0\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#3 Calculate Average Scores per Subject:\n",
    "avg_scores_per_subject = df.groupby('Subject')['Score'].mean()\n",
    "print(avg_scores_per_subject)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a779bc45-df7f-4063-acf3-618da846183d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student_ID     Name Grade  Subject  Score  GPA  Attendance_Rate\n",
      "0           1    Alice     A     Math     90  3.9               95\n",
      "5           6    Frank     A     Math     95  3.8               96\n",
      "2           3  Charlie     A     Math     85  3.7               90\n",
      "4           5      Eva     B  Science     88  3.5               92\n",
      "1           2      Bob     B  Science     80  3.4               88\n",
      "3           4    David     C  English     70  2.8               85\n"
     ]
    }
   ],
   "source": [
    "#4. Sort Students Based on Their Grades\n",
    "sorted_by_gpa = df.sort_values('GPA', ascending=False)\n",
    "print(sorted_by_gpa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "91a42319-6248-4801-9512-48c414ba7fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student_ID     Name Grade  Subject  Score  GPA  Attendance_Rate\n",
      "5           6    Frank     A     Math     95  3.8               96\n",
      "0           1    Alice     A     Math     90  3.9               95\n",
      "4           5      Eva     B  Science     88  3.5               92\n",
      "2           3  Charlie     A     Math     85  3.7               90\n",
      "1           2      Bob     B  Science     80  3.4               88\n",
      "3           4    David     C  English     70  2.8               85\n"
     ]
    }
   ],
   "source": [
    "#4. Sort Students Based on Their Attendance Rate\n",
    "sorted_by_attendance = df.sort_values('Attendance_Rate', ascending=False)\n",
    "print(sorted_by_attendance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1a6da-e248-4c35-a151-5719f68bf8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. Inventory Management\n",
    "Use Case: Analyze inventory data to optimize stock levels.\n",
    "Operations:\n",
    "Count total stock per item or category.\n",
    "Find the item with the highest or lowest stock levels.\n",
    "Calculate average stock usage per day or week.\n",
    "Sort items by their restock date or quantity in stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e89ff2b8-7f35-40e4-b102-45984c61912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item_ID Item_Name         Category  Stock_Level Restock_Date  \\\n",
      "0      101  Widget A      Electronics          150   2024-09-10   \n",
      "1      102  Widget B      Electronics           80   2024-09-15   \n",
      "2      103  Widget C      Accessories          200   2024-09-20   \n",
      "3      104  Widget D  Office Supplies           60   2024-09-25   \n",
      "4      105  Widget E      Electronics           90   2024-09-30   \n",
      "5      106  Widget F  Office Supplies           40   2024-10-05   \n",
      "\n",
      "   Stock_Usage_Per_Day  \n",
      "0                   10  \n",
      "1                    5  \n",
      "2                   20  \n",
      "3                    4  \n",
      "4                    7  \n",
      "5                    3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample inventory data\n",
    "data = {\n",
    "    'Item_ID': [101, 102, 103, 104, 105, 106],\n",
    "    'Item_Name': ['Widget A', 'Widget B', 'Widget C', 'Widget D', 'Widget E', 'Widget F'],\n",
    "    'Category': ['Electronics', 'Electronics', 'Accessories', 'Office Supplies', 'Electronics', 'Office Supplies'],\n",
    "    'Stock_Level': [150, 80, 200, 60, 90, 40],\n",
    "    'Restock_Date': pd.to_datetime(['2024-09-10', '2024-09-15', '2024-09-20', '2024-09-25', '2024-09-30', '2024-10-05']),\n",
    "    'Stock_Usage_Per_Day': [10, 5, 20, 4, 7, 3]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2f1b7fd8-ceab-4bda-8a39-88c95e7359de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Name\n",
      "Widget A    150\n",
      "Widget B     80\n",
      "Widget C    200\n",
      "Widget D     60\n",
      "Widget E     90\n",
      "Widget F     40\n",
      "Name: Stock_Level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count Total Stock per Item\n",
    "total_stock_per_item = df.groupby('Item_Name')['Stock_Level'].sum()\n",
    "print(total_stock_per_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ba7d6123-e1d2-4640-95fd-7526a9c0ad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Accessories        200\n",
      "Electronics        320\n",
      "Office Supplies    100\n",
      "Name: Stock_Level, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1. Count Total Stock per  Category:\n",
    "total_stock_per_category = df.groupby('Category')['Stock_Level'].sum()\n",
    "print(total_stock_per_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ae38c-3cea-4b87-a8ad-4180e6fe91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_stock_item = df.loc[df['Stock_Level'].idxmax()]\n",
    "print(highest_stock_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "499c1b1f-9107-4b75-9370-2c4ae7b1a6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_ID                                103\n",
      "Item_Name                         Widget C\n",
      "Category                       Accessories\n",
      "Stock_Level                            200\n",
      "Restock_Date           2024-09-20 00:00:00\n",
      "Stock_Usage_Per_Day                     20\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Item with the Highest Stock Levels:\n",
    "highest_stock_item = df.loc[df['Stock_Level'].idxmax()]\n",
    "print(highest_stock_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "46944c76-d980-4448-ab9b-eb4cedff730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_ID                                106\n",
      "Item_Name                         Widget F\n",
      "Category                   Office Supplies\n",
      "Stock_Level                             40\n",
      "Restock_Date           2024-10-05 00:00:00\n",
      "Stock_Usage_Per_Day                      3\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#2. Find the Item with the Lowest Stock Levels:\n",
    "lowest_stock_item = df.loc[df['Stock_Level'].idxmin()]\n",
    "print(lowest_stock_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ea72d600-1416-4b8a-b070-75f563f6d9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.166666666666666\n"
     ]
    }
   ],
   "source": [
    "#3. Calculate Average Stock Usage Per Day:\n",
    "\n",
    "avg_stock_usage_per_day = df['Stock_Usage_Per_Day'].mean()\n",
    "print(avg_stock_usage_per_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a20f9b68-8e97-48a0-8212-d2669ed0360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.166666666666664\n"
     ]
    }
   ],
   "source": [
    "#3. Average Stock Usage Per Week \n",
    "avg_stock_usage_per_week = avg_stock_usage_per_day * 7\n",
    "print(avg_stock_usage_per_week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6caf3047-9fb1-423a-9281-54e956f3c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item_ID Item_Name         Category  Stock_Level Restock_Date  \\\n",
      "0      101  Widget A      Electronics          150   2024-09-10   \n",
      "1      102  Widget B      Electronics           80   2024-09-15   \n",
      "2      103  Widget C      Accessories          200   2024-09-20   \n",
      "3      104  Widget D  Office Supplies           60   2024-09-25   \n",
      "4      105  Widget E      Electronics           90   2024-09-30   \n",
      "5      106  Widget F  Office Supplies           40   2024-10-05   \n",
      "\n",
      "   Stock_Usage_Per_Day  \n",
      "0                   10  \n",
      "1                    5  \n",
      "2                   20  \n",
      "3                    4  \n",
      "4                    7  \n",
      "5                    3  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Items by Their Restock Date\n",
    "sorted_by_restock_date = df.sort_values('Restock_Date')\n",
    "print(sorted_by_restock_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fb56d473-65c2-4ea0-8815-b1602cfbe725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Item_ID Item_Name         Category  Stock_Level Restock_Date  \\\n",
      "2      103  Widget C      Accessories          200   2024-09-20   \n",
      "0      101  Widget A      Electronics          150   2024-09-10   \n",
      "4      105  Widget E      Electronics           90   2024-09-30   \n",
      "1      102  Widget B      Electronics           80   2024-09-15   \n",
      "3      104  Widget D  Office Supplies           60   2024-09-25   \n",
      "5      106  Widget F  Office Supplies           40   2024-10-05   \n",
      "\n",
      "   Stock_Usage_Per_Day  \n",
      "2                   20  \n",
      "0                   10  \n",
      "4                    7  \n",
      "1                    5  \n",
      "3                    4  \n",
      "5                    3  \n"
     ]
    }
   ],
   "source": [
    "#4. Sort Items by Their Quantity in Stock:\n",
    "sorted_by_stock_level = df.sort_values('Stock_Level', ascending=False)\n",
    "print(sorted_by_stock_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe6dd4-e721-4e65-895e-86608f7a6768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
